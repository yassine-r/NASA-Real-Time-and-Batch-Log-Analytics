{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47195352",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark.sql.types import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6faf9e69",
   "metadata": {},
   "outputs": [],
   "source": [
    "cassandra_host = \"cassandra\"\n",
    "cassandra_user = \"cassandra\"\n",
    "cassandra_pwd  = \"cassandra\"\n",
    "cassandra_port = 9042\n",
    "key_space      = \"loganalysis\"\n",
    "table_name     = \"nasalog\"\n",
    "kafka_server   = \"kafka:9092\"\n",
    "kafka_topic    = \"nasa_logs\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3754df92",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder.appName(\"log_analytics\").\\\n",
    "config(\"spark.jars.packages\",\"org.apache.spark:spark-sql-kafka-0-10_2.12:3.0.0,com.datastax.spark:spark-cassandra-connector_2.12:3.0.0,com.datastax.spark:spark-cassandra-connector-driver_2.12:3.0.0\").\\\n",
    "config(\"spark.cassandra.connection.host\",cassandra_host).\\\n",
    "config(\"spark.cassandra.auth.username\",cassandra_user).\\\n",
    "config(\"spark.cassandra.auth.password\",cassandra_pwd).\\\n",
    "getOrCreate()\n",
    "\n",
    "\n",
    "\n",
    "kafka_stream = spark.readStream \\\n",
    "    .format(\"kafka\") \\\n",
    "    .option(\"kafka.bootstrap.servers\", kafka_server) \\\n",
    "    .option(\"subscribe\", kafka_topic) \\\n",
    "    .load()\n",
    "\n",
    "# Cast the Kafka message value as a string\n",
    "kafka_stream = kafka_stream.selectExpr(\"CAST(value AS STRING) as message\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d304cece",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess the text data and filter out rows with null values\n",
    "preprocessed_stream = kafka_stream.select(\n",
    "    regexp_extract('message', r'^([^\\s]+\\s)', 1).alias('host'),\n",
    "    to_timestamp(regexp_extract('message', r'^.*\\[(\\d\\d/\\w{3}/\\d{4}:\\d{2}:\\d{2}:\\d{2} -\\d{4})]', 1), 'dd/MMM/yyyy:HH:mm:ss Z').alias('time'),\n",
    "    regexp_extract('message', r'\"(.*?) [^\"]+\"', 1).alias('method'),\n",
    "    regexp_extract('message', r'^.*\"\\w+\\s+([^\\s]+)\\s+HTTP.*\"', 1).alias('path'),\n",
    "    regexp_extract('message', r'^.*\"\\s+([^\\s]+)', 1).cast('integer').alias('status'),\n",
    "    regexp_extract('message', r'^.*\\s+(\\d+)$', 1).cast('integer').alias('content_size'),\n",
    ").filter(\n",
    "    col('method').isNotNull() &\n",
    "    col('host').isNotNull() &\n",
    "    col('time').isNotNull() &\n",
    "    col('path').isNotNull() &\n",
    "    col('status').isNotNull() &\n",
    "    col('content_size').isNotNull()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "315b08c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the Cassandra write configuration\n",
    "cassandra_write_config = {\n",
    "    \"keyspace\": key_space,\n",
    "    \"table\": table_name,\n",
    "    \"mode\": \"append\",\n",
    "    \"spark.cassandra.connection.host\": cassandra_host,\n",
    "    \"spark.cassandra.auth.username\": cassandra_user,\n",
    "    \"spark.cassandra.auth.password\": cassandra_pwd,\n",
    "}\n",
    "\n",
    "# Write the preprocessed stream to Cassandra\n",
    "query_cassandra = preprocessed_stream.writeStream \\\n",
    "    .foreachBatch(lambda batch_df, batch_id: batch_df.write \\\n",
    "        .format(\"org.apache.spark.sql.cassandra\") \\\n",
    "        .options(**cassandra_write_config) \\\n",
    "        .mode(\"append\") \\\n",
    "        .save()) \\\n",
    "    .outputMode(\"append\") \\\n",
    "    .start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45afd717",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the HDFS write configuration\n",
    "hdfs_write_config = {\n",
    "    \"path\": \"hdfs://namenode:8020/output/nasa_logs/\", \n",
    "    \"format\": \"csv\",\n",
    "}\n",
    "\n",
    "# Write the preprocessed stream to HDFS\n",
    "query_hdfs = preprocessed_stream.writeStream \\\n",
    "    .format(\"csv\") \\\n",
    "    .options(**hdfs_write_config) \\\n",
    "    .outputMode(\"append\") \\\n",
    "    .option(\"checkpointLocation\", \"checkpoint/data\") \\\n",
    "    .start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c07c35cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start both streaming queries\n",
    "query_cassandra.awaitTermination()\n",
    "query_hdfs.awaitTermination()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
